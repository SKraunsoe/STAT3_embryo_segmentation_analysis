# STAT3_embryo_segmentation_analysis

Fiji macros, R script and links to Google Colab notebooks (3D Stardist segmentation) for the analysis of transcription factors (STAT3, TFCP2L1, NANOG) in E3.5, E4.5 and diapause mouse embryos via 3D stardist segmentation and 2D stardist segmentation + Trackmate (methods 1 and 2). 

This repository contains the Fiji macros and R script used to analyse and quantify the expression patterns of STAT3 and TFCP2L1 in mouse embryos which we use to support the qualitative observation that expression of STAT3 and its target, TFCP2L1 is enhanced in the ICM of diapaused mouse embryos. See our paper for more details. Two methods have been employed to achieve 3D segmentation of the nuclei present in the embryo both of which yield similar results. The first method, 3D stardist segmentation implements via Fiji and a GoogleColab notebook and requires an annotated training data set. The second method implements solely in Fiji and does not require a training data set provide images are sufficiently similar to the ones used to train the default 'Versatile (fluorescent nuclei) model. The macro scripts required to implement both methods are available at this repository in sub-folders. 


Method 1: 3D Stardist segmentation

There are four sections to this analysis pipeline which must be run in order. 

1. The first Fiji macro, "Image pre-processing macro to prepare images for 3D stardist segmentation.ijm" takes the raw 4-channel images (in tif format) and processes them so they are ready to be fed into the 3D Stardist segmentation script. If images are not in .tif format or have more than one channel, then the macro will need to be modified slighly to account for this. The 3D Image J Suite plugin (Ollion et al., 2013) is required to run the Fiji macros in this analysis. 

2. The second stage of the process involves using a Google Colab notebook developed by the Jacquemet and Henriques laboratories as part of the Zero-Cost Deep-Learning to Enhance Microscopy project (https://github.com/HenriquesLab/DeepLearning_Collab/wiki) (von Chamier et al., 2021). This notebook (https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb) uses the 3D Stardist segmentation algorith development by Martin Weigert and Uwe Schmidt (Weigert et al., 2019, Schmidt et al., 2018). The notebook facilitates all stages of the training of a model to segment unseen data but requires the training of a dataset of raw images and the corresponding segmentation which can be manually generated with tools such as the Labkit plugin in Fiji, which allow for easy annotation, or using existing segmented datasets from programmes such as MINS (Lou et al., 2014). Once the segmentation has been generated, you can export the .tif files from the Google Colab notebook. 

3. The second Fiji macro, "Image post-processing macro to generate 3D quantification data" combines the output of the segmentation with the raw image as an additional channel and then uses the 3D Image J Suite toolbox to quantify the intensity of the pixel values in each channel per segmented object (nuclei). The macro also measures morphological parameters (e.g., sphericity, volume, xyz coordinates) for each segmented object (nuclei). The data is exported as 5 separate csvs per image, one for the morphological data and one for each of the four channels.

4. The final stage of the analysis involves visualising the data using ggplot in R to generate violin plots of expression levels in different embryo stages, plotly to generate 3D in silico representations of the embryos colour coded by expression values and the fsh function to isolate and localise nuclei with high expression values for particular transcription factors. This script could be adapted to generate differnt styles of graphs. The following R packages are required to run this analysis: tidyverse, ggplot2, BiocManager, limma, org.Mm.eg.db, readr, dplyr, data.table, plotly, factoextra, viridis, reshape2, gplots, ggpubr, remotes, data.table, plotly, factoextra, reshape2, gatepoints. 



Method 2: 2D Stardist segmentation + Trackmate
1. The first Fiji macro, "Image processing macro to generate 2D stardist segmentation on each slice as a separate channel.ijm" takes the raw 4-channel images (in tif format), performs an unsharp mask, re-orders the hyper-stack (Stardist can only accept 2D images + time not 3D stacks) and performs 2D Stardist segmentation on each channel of the image. Depending on the size of the image this can take several minutes. 

2. The second macro "Image processing macro to generate 3D objects using Trackmate.ijm" takes the 5-channel image output from the first macro and opens the Trackmate plugin for the user to manually navigate through (this plugin is not yet macro recordable). Detailed notes on how to navigate through the plugin are included in the macro script. Once Trackmate has been implemented, the macro will then automatically use the 3D Image J Suite toolbox to quantify the intensity of the pixel values in each channel per segmented object (nuclei). The macro also measures morphological parameters (e.g., sphericity, volume, xyz coordinates) for each segmented object (nuclei). The data is exported as 5 separate csvs per image, one for the morphological data and one for each of the four channels.

Note: The TrackMate plugin has a Stardist detector built in which can be used to simplify the number of different macro scripts that need running however, this can take several minutes to run per image and due to the need for manual input, it was quicker to achieve 2D segmentation on each slice separately with the Stardist plugin and then use the Label image detector. This also allows for the user to select parameters in the Stardist plugin to vary the overlap and probability functions. 

3. The final stage of the analysis involves visualising the data using ggplot in R to generate violin plots of expression levels in different embryo stages, plotly to generate 3D in silico representations of the embryos colour coded by expression values and the fsh function to isolate and localise nuclei with high expression values for particular transcription factors. This script could be adapted to generate differnt styles of graphs. The following R packages are required to run this analysis: tidyverse, ggplot2, BiocManager, limma, org.Mm.eg.db, readr, dplyr, data.table, plotly, factoextra, viridis, reshape2, gplots, ggpubr, remotes, data.table, plotly, factoextra, reshape2, gatepoints. 

References:
1. Lou, X., Kang, M., Xenopoulos, P., Muñoz-Descalzo, S., & Hadjantonakis, A. K. (2014). A Rapid and Efficient 2D/3D Nuclear Segmentation Method for Analysis of Early Mouse Embryo and Stem Cell Image Data. Stem Cell Reports, 2(3), 382–397. https://doi.org/10.1016/J.STEMCR.2014.01.010
2. Ollion, J., Cochennec, J., Loll, F., Escudé, C., & Boudier, T. (2013). TANGO: A generic tool for high-throughput 3D image analysis for studying nuclear organization. Bioinformatics, 29(14), 1840–1841. https://doi.org/10.1093/bioinformatics/btt276
3. Pietzsch, T., Saalfeld, S., Preibisch, S., & Tomancak, P. (2015). BigDataViewer: Visualization and processing for large image data sets. In Nature Methods (Vol. 12, Issue 6, pp. 481–483). Nature Publishing Group. https://doi.org/10.1038/nmeth.3392
4. Schmid, B., Schindelin, J., Cardona, A., Longair, M., & Heisenberg, M. (2010). A high-level 3D visualization API for Java and ImageJ. BMC Bioinformatics, 11(1), 1–7. https://doi.org/10.1186/1471-2105-11-274/FIGURES/5
5. Schmidt, U., Weigert, M., Broaddus, C., & Myers, G. (2018). Cell Detection with Star-convex Polygons. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 11071 LNCS, 265–273. https://doi.org/10.1007/978-3-030-00934-2_30
6. von Chamier, L., Laine, R. F., Jukkala, J., Spahn, C., Krentzel, D., Nehme, E., Lerche, M., Hernández-Pérez, S., Mattila, P. K., Karinou, E., Holden, S., Solak, A. C., Krull, A., Buchholz, T.-O., Jones, M. L., Royer, L. A., Leterrier, C., Shechtman, Y., Jug, F., … Henriques, R. (2021). Democratising deep learning for microscopy with ZeroCostDL4Mic. Nature Communications, 12(1), 2276. https://doi.org/10.1038/s41467-021-22518-0
7. Weigert, M., Schmidt, U., Haase, R., Sugawara, K., & Myers, G. (2020). Star-convex polyhedra for 3D object detection and segmentation in microscopy. Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020, 3655–3662. https://doi.org/10.1109/WACV45572.2020.9093435
8. Wickham, H. (2016). ggplot2. https://doi.org/10.1007/978-3-319-24277-4
9. Ershov, D., Phan, M.-S., Pylvänäinen, J. W., Rigaud, S. U., Blanc, L. Le, Charles-Orszag, A., Conway, J. R. W., Laine, R. F., Roy, N. H., Bonazzi, D., Duménil, G., Jacquemet, G., & Tinevez, J.-Y. (2021). Bringing TrackMate into the era of machine-learning and deep-learning. BioRxiv, 2021.09.03.458852. https://doi.org/10.1101/2021.09.03.458852
